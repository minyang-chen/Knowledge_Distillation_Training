{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShLV9mW6_wQx"
   },
   "source": [
    "## Knowledge Distillation (Training Teacher and Student Model)\n",
    "\n",
    "A classic example of model compression can be seen in various BERT models that employ knowledge distillation to compress their large deep models into lightweight versions of BERT. \n",
    "\n",
    "Knowledge_Distillation_Training\n",
    "\n",
    "In this project, DistilBERT is a natural candidate to initialize the student with since it has 40% fewer parameters and has been shown to achieve strong results on downstream tasks.  Smaller model than teacher for the student to reduce the latency and memory footprint. Knowledge distillation functions best when the teacher and learner are of the same model type. (BERT and RoBERTa, can have different output embedding spaces which creates issues for student to mimic the teacher)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ScgwidU7BCmq"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install datasets\n",
    "#!pip install transformers[torch]\n",
    "#!pip install accelerate>=0.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XLxPXtH0_xnb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer,TrainingArguments, pipeline, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, load_metric\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: {'text': 'what expression would i use to say i love you if i were an italian', 'intent': 61}\n",
      "intent  : translate\n",
      "labels  : 151\n"
     ]
    }
   ],
   "source": [
    "#The CLINC150 dataset consists of a query in the text column and its corresponding intent\n",
    "clinc = load_dataset(\"clinc_oos\", \"plus\")\n",
    "sample = clinc[\"train\"][0]\n",
    "print(\"question:\",sample)\n",
    "intents = clinc[\"train\"].features[\"intent\"]\n",
    "intent = intents.int2str(sample[\"intent\"])\n",
    "print(\"intent  :\",intent)\n",
    "\n",
    "num_labels = intents.num_classes\n",
    "print(\"labels  :\",num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_checkpoint = \"distilbert-base-uncased\"\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(batch):\n",
    "  return student_tokenizer(batch[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a086aa41e649219dd658685ef824da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clinc_tokenized = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"])\n",
    "clinc_tokenized = clinc_tokenized.rename_column(\"intent\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training\n",
    "Create trainer class and loss function compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xjHjc3e-B5Xf"
   },
   "outputs": [],
   "source": [
    "class KnowledgeDistillationTrainingArguments(TrainingArguments):\n",
    "  def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.alpha = alpha\n",
    "    self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eDsHhoN3DHkb"
   },
   "outputs": [],
   "source": [
    "class KnowledgeDistillationTrainer(Trainer):\n",
    "  def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.teacher_model = teacher_model\n",
    "\n",
    "  def compute_loss(self, model, inputs, return_outputs=False):\n",
    "    #Extract cross-entropy loss and logits from student\n",
    "    outputs_student = model(**inputs)\n",
    "    loss_ce = outputs_student.loss\n",
    "    logits_student = outputs_student.logits\n",
    "    # Extract logits from teacher\n",
    "    outputs_teacher = self.teacher_model(**inputs)\n",
    "    logits_teacher = outputs_teacher.logits\n",
    "     #Computing distillation loss by Softening probabilities\n",
    "    loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    loss_kd = self.args.temperature ** 2 * loss_fct(\n",
    "                F.log_softmax(logits_student / self.args.temperature, dim=-1),\n",
    "                F.softmax(logits_teacher / self.args.temperature, dim=-1))\n",
    "\n",
    "    loss = self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd\n",
    "    return (loss, outputs_student) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HpUI6EZiKK-p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_235380/3260035165.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy_score = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  predictions, labels = pred\n",
    "  predictions = np.argmax(predictions, axis=1)\n",
    "  return accuracy_score.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNXBLatvKcmv"
   },
   "source": [
    "In this function, the predictions from the sequence modeling head come in the form of logits, so we use the np.argmax() function to find the most confident class predicâ€ tion and compare that against the ground truth label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "H7epVe7uKmBb"
   },
   "outputs": [],
   "source": [
    "batch_size = 48\n",
    "finetuned_student_ckpt = \"distilbert-base-uncased-finetuned-clinc-student\"\n",
    "\n",
    "## Training Arguments for DistillationTrainer\n",
    "student_training_args = KnowledgeDistillationTrainingArguments(\n",
    "    output_dir=finetuned_student_ckpt, \n",
    "    evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs=3, \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, \n",
    "    alpha=1, \n",
    "    weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_pwSM8aPb4r"
   },
   "source": [
    "### Teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xfZFhd-_PVCX"
   },
   "outputs": [],
   "source": [
    "teacher_checkpoint = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "teacher_model = (AutoModelForSequenceClassification.from_pretrained(teacher_checkpoint, \n",
    "                                                                    num_labels=num_labels).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-DTzbcvNLdX"
   },
   "source": [
    "### Student model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CXrAiUxnKv1v"
   },
   "outputs": [],
   "source": [
    "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=bert_ckpt)\n",
    "\n",
    "## mappings between each intent and label ID.\n",
    "id2label = pipe.model.config.id2label\n",
    "label2id = pipe.model.config.label2id\n",
    "\n",
    "student_config = (AutoConfig.from_pretrained(student_checkpoint, \n",
    "                                             num_labels=num_labels,\n",
    "                                             id2label=id2label, \n",
    "                                             label2id=label2id))\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def student_init():\n",
    "  return (AutoModelForSequenceClassification.from_pretrained(student_checkpoint, \n",
    "                                                             config=student_config).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "N-vXAa1iPqJ9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[codecarbon INFO @ 05:12:03] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 05:12:03] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 05:12:03] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 05:12:03] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 05:12:03] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 05:12:04] We saw that you have a AMD Ryzen 7 5700G with Radeon Graphics but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 05:12:04] CPU Model on constant consumption mode: AMD Ryzen 7 5700G with Radeon Graphics\n",
      "[codecarbon INFO @ 05:12:04] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 05:12:04]   Platform system: Linux-6.4.6-76060406-generic-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 05:12:04]   Python version: 3.10.12\n",
      "[codecarbon INFO @ 05:12:04]   CodeCarbon version: 2.2.3\n",
      "[codecarbon INFO @ 05:12:04]   Available RAM : 93.640 GB\n",
      "[codecarbon INFO @ 05:12:04]   CPU count: 16\n",
      "[codecarbon INFO @ 05:12:04]   CPU model: AMD Ryzen 7 5700G with Radeon Graphics\n",
      "[codecarbon INFO @ 05:12:04]   GPU count: 1\n",
      "[codecarbon INFO @ 05:12:04]   GPU model: 1 x NVIDIA GeForce RTX 3090\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmychen76\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pop/development/mclab-pretrain/knowledge_distillation/wandb/run-20231009_051209-4vx6ecdb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mychen76/huggingface/runs/4vx6ecdb' target=\"_blank\">eager-shape-51</a></strong> to <a href='https://wandb.ai/mychen76/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mychen76/huggingface' target=\"_blank\">https://wandb.ai/mychen76/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mychen76/huggingface/runs/4vx6ecdb' target=\"_blank\">https://wandb.ai/mychen76/huggingface/runs/4vx6ecdb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='954' max='954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [954/954 01:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.420913</td>\n",
       "      <td>0.707742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.894200</td>\n",
       "      <td>2.334888</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.894200</td>\n",
       "      <td>2.009495</td>\n",
       "      <td>0.834194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 05:12:28] Energy consumed for RAM : 0.000146 kWh. RAM Power : 35.114836692810066 W\n",
      "[codecarbon INFO @ 05:12:28] Energy consumed for all GPUs : 0.001390 kWh. Total GPU Power : 333.46700000000004 W\n",
      "[codecarbon INFO @ 05:12:28] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 05:12:28] 0.001713 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 05:12:43] Energy consumed for RAM : 0.000293 kWh. RAM Power : 35.114836692810066 W\n",
      "[codecarbon INFO @ 05:12:43] Energy consumed for all GPUs : 0.002773 kWh. Total GPU Power : 332.04900000000004 W\n",
      "[codecarbon INFO @ 05:12:43] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 05:12:43] 0.003420 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 05:12:58] Energy consumed for RAM : 0.000439 kWh. RAM Power : 35.114836692810066 W\n",
      "[codecarbon INFO @ 05:12:58] Energy consumed for all GPUs : 0.004155 kWh. Total GPU Power : 331.87500000000006 W\n",
      "[codecarbon INFO @ 05:12:58] Energy consumed for all CPUs : 0.000531 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 05:12:58] 0.005126 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 05:13:13] Energy consumed for RAM : 0.000585 kWh. RAM Power : 35.114836692810066 W\n",
      "[codecarbon INFO @ 05:13:13] Energy consumed for all GPUs : 0.005544 kWh. Total GPU Power : 333.282 W\n",
      "[codecarbon INFO @ 05:13:13] Energy consumed for all CPUs : 0.000708 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 05:13:13] 0.006837 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 05:13:27] Energy consumed for RAM : 0.000725 kWh. RAM Power : 35.114836692810066 W\n",
      "[codecarbon INFO @ 05:13:27] Energy consumed for all GPUs : 0.006913 kWh. Total GPU Power : 344.937 W\n",
      "[codecarbon INFO @ 05:13:27] Energy consumed for all CPUs : 0.000877 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 05:13:27] 0.008515 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 1.81 s, total: 1min 19s\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=954, training_loss=3.1499722078911163, metrics={'train_runtime': 79.4697, 'train_samples_per_second': 575.691, 'train_steps_per_second': 12.005, 'total_flos': 247836315084876.0, 'train_loss': 3.1499722078911163, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "distilbert_trainer = KnowledgeDistillationTrainer(\n",
    "    model_init=student_init,\n",
    "    teacher_model=teacher_model, \n",
    "    args=student_training_args,\n",
    "    train_dataset=clinc_tokenized['train'], \n",
    "    eval_dataset=clinc_tokenized['validation'],\n",
    "    compute_metrics=compute_metrics, \n",
    "    tokenizer=student_tokenizer)\n",
    "\n",
    "distilbert_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save training result model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tY0C3ZsdIVaK"
   },
   "outputs": [],
   "source": [
    "teacher_model_id_or_path=\"./result/teacher_model\"\n",
    "student_model_id_or_path=\"./result/student_model\"\n",
    "\n",
    "teacher_model.save_pretrained(teacher_model_id_or_path)\n",
    "distilbert_trainer.save_model(student_model_id_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saved training log\n",
    "TrainOutput(global_step=954, training_loss=3.1499722078911163, metrics={'train_runtime': 79.4697, 'train_samples_per_second': 575.691, 'train_steps_per_second': 12.005, 'total_flos': 247836315084876.0, 'train_loss': 3.1499722078911163, 'epoch': 3.0})\n",
    "```\n",
    "Epoch Training Loss \tValidation Loss \tAccuracy\n",
    "1 \t   No log           3.420913 \t        0.707742\n",
    "2 \t   3.894200 \t    2.334888 \t        0.816452\n",
    "3 \t   3.894200 \t    2.009495 \t        0.834194\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKOilJSN-M3d"
   },
   "source": [
    "### Verify Teacher and Student Model\n",
    "compare the two models based on size and inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "L7LJRPRzJkOg"
   },
   "outputs": [],
   "source": [
    "def compute_parameters(model_path):\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "  parameters = model.num_parameters()\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving in model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8-leprTuIE2w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model:  109598359\n",
      "Student Model:  67069591\n",
      "difference in parameters: -38.804201438818986\n"
     ]
    }
   ],
   "source": [
    "teacher_model_parameters = compute_parameters(model_path=teacher_model_id_or_path)\n",
    "print(\"Teacher Model: \", teacher_model_parameters)\n",
    "\n",
    "student_model_parameters = compute_parameters(model_path=student_model_id_or_path)\n",
    "print(\"Student Model: \", student_model_parameters)\n",
    "\n",
    "decrease = (student_model_parameters-teacher_model_parameters)/teacher_model_parameters\n",
    "print(\"difference in parameters:\",decrease*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "zQsbyCP7Lfgc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model File Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 439MB\n",
      "drwxrwxr-x 2 pop pop   1MB Oct  9 05:17 .\n",
      "drwxrwxr-x 4 pop pop   1MB Oct  9 05:17 ..\n",
      "-rw-rw-r-- 1 pop pop   1MB Oct  9 05:18 config.json\n",
      "-rw-rw-r-- 1 pop pop 439MB Oct  9 05:18 pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "## file size reduction \n",
    "!echo 'Teacher Model File Size'\n",
    "!ls ./result/teacher_model -al --block-size=MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model File Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 270MB\n",
      "drwxrwxr-x 2 pop pop   1MB Oct  9 05:17 .\n",
      "drwxrwxr-x 4 pop pop   1MB Oct  9 05:17 ..\n",
      "-rw-rw-r-- 1 pop pop   1MB Oct  9 05:18 added_tokens.json\n",
      "-rw-rw-r-- 1 pop pop   1MB Oct  9 05:18 config.json\n",
      "-rw-rw-r-- 1 pop pop 269MB Oct  9 05:18 pytorch_model.bin\n",
      "-rw-rw-r-- 1 pop pop   1MB Oct  9 05:18 special_tokens_map.json\n",
      "-rw-rw-r-- 1 pop pop   1MB Oct  9 05:18 tokenizer_config.json\n",
      "-rw-rw-r-- 1 pop pop   1MB Oct  9 05:18 tokenizer.json\n",
      "-rw-rw-r-- 1 pop pop   1MB Oct  9 05:18 training_args.bin\n",
      "-rw-rw-r-- 1 pop pop   1MB Oct  9 05:18 vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!echo 'Student Model File Size'\n",
    "!ls ./result/student_model -al --block-size=MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Og3MC2FOMh_S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i would like to know the proper way to greet an adult in portuguese\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "## spot check a sample\n",
    "print(clinc['train']['text'][11])\n",
    "print(clinc['train']['intent'][11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving in inference performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "22AhklIhOEFL"
   },
   "outputs": [],
   "source": [
    "def performance_test(model_id_or_path,model_type,tokenizer_id):\n",
    "    print(\"performance_test: \",model_id_or_path)\n",
    "    pipe = pipeline(\"text-classification\", model=model_id_or_path, tokenizer=tokenizer_id)\n",
    "    sample_input = clinc['train']['text'][11]\n",
    "    for _ in range(10):\n",
    "        _ = pipe(sample_input)\n",
    "    ## run test\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = pipe(sample_input)\n",
    "    total_time = time.time()-start\n",
    "    print(F\"Total time to process 100 requests for {model_type}: \",total_time)\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ND0Rk_c-Od-s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance_test:  ./result/teacher_model\n",
      "Total time to process 100 requests for Teacher Model:  3.7654707431793213\n",
      "performance_test:  ./result/student_model\n",
      "Total time to process 100 requests for Student Model:  1.9501032829284668\n",
      "saving in inference time: 48.2109033389561 %\n"
     ]
    }
   ],
   "source": [
    "# teacher model test\n",
    "teacher_total_time = performance_test(teacher_model_id_or_path,model_type=\"Teacher Model\",tokenizer_id='bert-base-uncased')\n",
    "\n",
    "# student model test\n",
    "student_total_time = performance_test(student_model_id_or_path,model_type=\"Student Model\",  tokenizer_id=\"distilbert-base-uncased\")\n",
    "\n",
    "# compute saving\n",
    "changes_in_time = (teacher_total_time-student_total_time)/teacher_total_time\n",
    "print(\"saving in inference time:\",changes_in_time*100, \"%\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## log result\n",
    "\n",
    "performance_test:  ./result/teacher_model\n",
    "Total time to process 100 requests for Teacher Model:  3.764711618423462\n",
    "performance_test:  ./result/student_model\n",
    "Total time to process 100 requests for Student Model:  1.916383981704712\n",
    "saving in inference time: 49.096128045334034 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
